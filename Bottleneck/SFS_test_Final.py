import numpy as np
import pandas
from math import log10
from scipy.optimize import minimize
import matplotlib.pyplot as plt

empirical = (pandas.read_csv("sfsFinal.csv", sep = " ", header  = None))
empirical = np.array(empirical.iloc[:,1])
empirical = np.insert(empirical, 0, 100000000 - np.sum(empirical))
empirical  = empirical/np.sum(empirical)
mu = 1.4*(10**-8)
print(empirical)
def C(n: int) -> np.ndarray:
    r"""The combinatorial matrix :math:`\mathbf C` defined in the paper's
    appendix.

    Args:
        n: the number of sampled haplotypes :math:`n`

    Returns:
        :math:`(n-1)\times(n-1)` matrix

    """
    W1 = np.zeros((n - 1, n - 1))
    W2 = np.zeros((n - 1, n - 1))
    b = np.arange(1, n - 1 + 1)
    # j = 2
    W1[:, 0] = (6 / (n + 1))
    W2[:, 0] = (0)
    # j = 3
    W1[:, 1] = (10 * (5 * n - 6 * b - 4) / (n + 2) / (n + 1))
    W2[:, 1] = ((20 * (n - 2)) / (n + 1) / (n + 2))
    for col in range(n - 3):
        # this cast is crucial for floating point precision
        j = np.float64(col + 2)
        # procedurally generated by Zeilberger's algorithm in Mathematica
        W1[:, col + 2] = (
            -(
                (
                    -(
                        (-1 + j)
                        * (1 + j) ** 2
                        * (3 + 2 * j)
                        * (j - n)
                        * (
                            4
                            + 2 * j
                            - 2 * b * j
                            + j**2
                            - b * j**2
                            + 4 * n
                            + 2 * j * n
                            + j**2 * n
                        )
                        * W1[:, col]
                    )
                    - (-1 + 2 * j)
                    * (3 + 2 * j)
                    * (
                        -4 * j
                        - 12 * b * j
                        - 4 * b**2 * j
                        - 6 * j**2
                        - 12 * b * j**2
                        - 2 * b**2 * j**2
                        - 4 * j**3
                        + 4 * b**2 * j**3
                        - 2 * j**4
                        + 2 * b**2 * j**4
                        + 4 * n
                        + 2 * j * n
                        - 6 * b * j * n
                        + j**2 * n
                        - 9 * b * j**2 * n
                        - 2 * j**3 * n
                        - 6 * b * j**3 * n
                        - j**4 * n
                        - 3 * b * j**4 * n
                        + 4 * n**2
                        + 6 * j * n**2
                        + 7 * j**2 * n**2
                        + 2 * j**3 * n**2
                        + j**4 * n**2
                    )
                    * W1[:, col + 1]
                )
                / (
                    j**2
                    * (2 + j)
                    * (-1 + 2 * j)
                    * (1 + j + n)
                    * (3 + b + j**2 - b * j**2 + 3 * n + j**2 * n)
                )
            )
        )  # noqa: E501
        W2[:, col + 2] = (
            (
                (-1 + j)
                * (1 + j)
                * (2 + j)
                * (3 + 2 * j)
                * (j - n)
                * (1 + j - n)
                * (1 + j + n)
                * W2[:, col]
                + (-1 + 2 * j)
                * (3 + 2 * j)
                * (1 + j - n)
                * (j + n)
                * (
                    2
                    - j
                    - 2 * b * j
                    - j**2
                    - 2 * b * j**2
                    + 2 * n
                    + j * n
                    + j**2 * n
                )
                * W2[:, col + 1]
            )
            / ((-1 + j) * j * (2 + j) * (-1 + 2 * j) * (j - n) * (j + n) * (1 + j + n))
        )  # noqa: E501

    return W1 - W2


def M(n: int, t: np.ndarray, y: np.ndarray) -> np.ndarray:
    r"""The matrix :math:`\mathbf M` defined in the paper's appendix

    Args:
        n: the number of sampled haplotypes :math:`n`
        t: time grid, starting at zero and ending at np.inf
        y: population size in each epoch

    Returns:
        :math:`(n-1)\times m` matrix, where :math:`m` is the number of epochs
        (the length of the ``y`` argument)

    """
    # epoch durations
    s = np.diff(t)
    # we handle the final infinite epoch carefully to facilitate autograd
    u = np.exp(-s[:-1] / y[:-1])
    u = np.concatenate((np.array([1]), u, np.array([0])))

    n_range = np.arange(2, n + 1)
    binom_vec = n_range * (n_range - 1) / 2

    return (
        np.exp(
            binom_vec[:, np.newaxis] * np.cumsum(np.log(u[np.newaxis, :-1]), axis=1)
            - np.log(binom_vec[:, np.newaxis])
        )
        @ (np.eye(len(y), k=0) - np.eye(len(y), k=-1))
        @ np.diag(y)
    )


CC = C(44)


def negloglieklihoodfunction(args):
    recentne = 10**args[0]
    oldne = 10**args[1]
    breakpointt = 10**args[2]

    MM = M(44, np.array([0, breakpointt, np.inf]), np.array([recentne,oldne]))

    expected = (np.matmul(CC,np.matmul(MM, np.array([[mu],[ mu]]))))
    expected = np.insert(expected, 0, 1.0 - np.sum(expected))

    return (empirical * np.log(empirical / expected)).sum()

res = minimize(negloglieklihoodfunction, [3,4,1.5],  #think more about parameterization and optimization method.
            method='Nelder-Mead', options = {"xatol" : 1e-16})
print(res)

a = (10**res.x)
a[0] = a[0]/2
a[1] = a[1]/2
print(a)
print(res)
"""
B = 0
for oldd in np.arange(88000, 98000, 500):
    for recent in np.arange(20000, 32000, 500):
        for breakk in np.arange(1000, 5000,  40):
            bb = negloglieklihoodfunction([np.log10(recent) , np.log10(oldd) ,np.log10(breakk)  ] )
            if bb < 1.25e-6:
                print(recent, oldd, breakk, bb)
                B = B +1
                
"""
